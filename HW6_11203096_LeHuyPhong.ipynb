{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRjzUSmQCiSk",
    "outputId": "8e8a8e60-70d5-47cb-c1fb-23c186cf3bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:01<00:00, 18698696.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 323233.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:00<00:00, 5422097.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 919837.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Thiết lập các thông số\n",
    "batch_size = 32 #100\n",
    "image_size = 28\n",
    "num_channels = 1\n",
    "latent_size = 100  # Kích thước của vector nhiễu đầu vào cho GAN\n",
    "\n",
    "# Tải và chuẩn bị dữ liệu\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Fashion-MNIST dataset từ torchvision\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "data_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zp6sf4FvCi6c"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size, num_channels, image_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_size, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, num_channels * image_size * image_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img.view(img.size(0), self.image_size, self.image_size, num_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdMqIRgHCkrZ"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channels, image_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_channels * image_size * image_size, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhASVUD_CnEp"
   },
   "outputs": [],
   "source": [
    "class cGAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator):\n",
    "        super(cGAN, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def forward(self, z):\n",
    "        gen_imgs = self.generator(z)\n",
    "        validity = self.discriminator(gen_imgs)\n",
    "        return validity, gen_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vx69n-jsCog6",
    "outputId": "83d3417c-c1f6-4842-efaa-6cc8b1f1e05d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10] [Batch 0/1875] [D loss: 0.6997385025024414] [G loss: 0.6828347444534302]\n",
      "[Epoch 0/10] [Batch 100/1875] [D loss: 0.32996803522109985] [G loss: 3.225648880004883]\n",
      "[Epoch 0/10] [Batch 200/1875] [D loss: 0.6210465431213379] [G loss: 2.058178663253784]\n",
      "[Epoch 0/10] [Batch 300/1875] [D loss: 0.4239850640296936] [G loss: 2.4694926738739014]\n",
      "[Epoch 0/10] [Batch 400/1875] [D loss: 0.5436300039291382] [G loss: 2.7170779705047607]\n",
      "[Epoch 0/10] [Batch 500/1875] [D loss: 0.4350687861442566] [G loss: 1.9119446277618408]\n",
      "[Epoch 0/10] [Batch 600/1875] [D loss: 0.6916693449020386] [G loss: 2.5703091621398926]\n",
      "[Epoch 0/10] [Batch 700/1875] [D loss: 0.4044649600982666] [G loss: 2.115946054458618]\n",
      "[Epoch 0/10] [Batch 800/1875] [D loss: 0.49662554264068604] [G loss: 1.8209400177001953]\n",
      "[Epoch 0/10] [Batch 900/1875] [D loss: 0.5750242471694946] [G loss: 0.9466201663017273]\n",
      "[Epoch 0/10] [Batch 1000/1875] [D loss: 0.5600942373275757] [G loss: 1.341071605682373]\n",
      "[Epoch 0/10] [Batch 1100/1875] [D loss: 0.587748646736145] [G loss: 2.771207332611084]\n",
      "[Epoch 0/10] [Batch 1200/1875] [D loss: 0.5583585500717163] [G loss: 1.2660176753997803]\n",
      "[Epoch 0/10] [Batch 1300/1875] [D loss: 0.4520244598388672] [G loss: 2.1111927032470703]\n",
      "[Epoch 0/10] [Batch 1400/1875] [D loss: 0.5338351130485535] [G loss: 1.2117023468017578]\n",
      "[Epoch 0/10] [Batch 1500/1875] [D loss: 0.6003775596618652] [G loss: 1.6360384225845337]\n",
      "[Epoch 0/10] [Batch 1600/1875] [D loss: 0.588347315788269] [G loss: 1.4700618982315063]\n",
      "[Epoch 0/10] [Batch 1700/1875] [D loss: 0.5125905275344849] [G loss: 1.7997814416885376]\n",
      "[Epoch 0/10] [Batch 1800/1875] [D loss: 0.5597788691520691] [G loss: 1.9766391515731812]\n",
      "[Epoch 1/10] [Batch 0/1875] [D loss: 0.5444509983062744] [G loss: 1.9284569025039673]\n",
      "[Epoch 1/10] [Batch 100/1875] [D loss: 0.4949134886264801] [G loss: 1.6388906240463257]\n",
      "[Epoch 1/10] [Batch 200/1875] [D loss: 0.5814403295516968] [G loss: 1.6226285696029663]\n",
      "[Epoch 1/10] [Batch 300/1875] [D loss: 0.6058975458145142] [G loss: 1.9101009368896484]\n",
      "[Epoch 1/10] [Batch 400/1875] [D loss: 0.5346616506576538] [G loss: 1.2196407318115234]\n",
      "[Epoch 1/10] [Batch 500/1875] [D loss: 0.5191935300827026] [G loss: 1.3838210105895996]\n",
      "[Epoch 1/10] [Batch 600/1875] [D loss: 0.5764132738113403] [G loss: 1.1178247928619385]\n",
      "[Epoch 1/10] [Batch 700/1875] [D loss: 0.629307210445404] [G loss: 1.5858659744262695]\n",
      "[Epoch 1/10] [Batch 800/1875] [D loss: 0.6199548840522766] [G loss: 2.18213152885437]\n",
      "[Epoch 1/10] [Batch 900/1875] [D loss: 0.5701252222061157] [G loss: 1.2097795009613037]\n",
      "[Epoch 1/10] [Batch 1000/1875] [D loss: 0.5498205423355103] [G loss: 1.723680853843689]\n",
      "[Epoch 1/10] [Batch 1100/1875] [D loss: 0.60166335105896] [G loss: 0.8328741192817688]\n",
      "[Epoch 1/10] [Batch 1200/1875] [D loss: 0.6780351996421814] [G loss: 1.1181749105453491]\n",
      "[Epoch 1/10] [Batch 1300/1875] [D loss: 0.6483239531517029] [G loss: 0.9698301553726196]\n",
      "[Epoch 1/10] [Batch 1400/1875] [D loss: 0.5829609632492065] [G loss: 1.943052887916565]\n",
      "[Epoch 1/10] [Batch 1500/1875] [D loss: 0.5796705484390259] [G loss: 1.3578996658325195]\n",
      "[Epoch 1/10] [Batch 1600/1875] [D loss: 0.5968198180198669] [G loss: 1.4390549659729004]\n",
      "[Epoch 1/10] [Batch 1700/1875] [D loss: 0.6317368745803833] [G loss: 1.2994310855865479]\n",
      "[Epoch 1/10] [Batch 1800/1875] [D loss: 0.5878193378448486] [G loss: 1.4154293537139893]\n",
      "[Epoch 2/10] [Batch 0/1875] [D loss: 0.6428300142288208] [G loss: 1.1289310455322266]\n",
      "[Epoch 2/10] [Batch 100/1875] [D loss: 0.6177013516426086] [G loss: 1.2425627708435059]\n",
      "[Epoch 2/10] [Batch 200/1875] [D loss: 0.5639441609382629] [G loss: 1.311288833618164]\n",
      "[Epoch 2/10] [Batch 300/1875] [D loss: 0.5760675072669983] [G loss: 1.2680250406265259]\n",
      "[Epoch 2/10] [Batch 400/1875] [D loss: 0.5972204208374023] [G loss: 1.0953876972198486]\n",
      "[Epoch 2/10] [Batch 500/1875] [D loss: 0.5510321855545044] [G loss: 1.4600178003311157]\n",
      "[Epoch 2/10] [Batch 600/1875] [D loss: 0.5458170175552368] [G loss: 1.3909574747085571]\n",
      "[Epoch 2/10] [Batch 700/1875] [D loss: 0.5642085075378418] [G loss: 1.2018311023712158]\n",
      "[Epoch 2/10] [Batch 800/1875] [D loss: 0.623809814453125] [G loss: 1.6975524425506592]\n",
      "[Epoch 2/10] [Batch 900/1875] [D loss: 0.5659997463226318] [G loss: 1.340652346611023]\n",
      "[Epoch 2/10] [Batch 1000/1875] [D loss: 0.5229964256286621] [G loss: 1.4854450225830078]\n",
      "[Epoch 2/10] [Batch 1100/1875] [D loss: 0.6607062220573425] [G loss: 1.0696274042129517]\n",
      "[Epoch 2/10] [Batch 1200/1875] [D loss: 0.7243536710739136] [G loss: 1.1768746376037598]\n",
      "[Epoch 2/10] [Batch 1300/1875] [D loss: 0.48204100131988525] [G loss: 1.4947497844696045]\n",
      "[Epoch 2/10] [Batch 1400/1875] [D loss: 0.7297213673591614] [G loss: 0.8980603218078613]\n",
      "[Epoch 2/10] [Batch 1500/1875] [D loss: 0.5940609574317932] [G loss: 1.31290602684021]\n",
      "[Epoch 2/10] [Batch 1600/1875] [D loss: 0.5666880011558533] [G loss: 1.6382352113723755]\n",
      "[Epoch 2/10] [Batch 1700/1875] [D loss: 0.5554885268211365] [G loss: 1.0792372226715088]\n",
      "[Epoch 2/10] [Batch 1800/1875] [D loss: 0.5766196250915527] [G loss: 1.2896606922149658]\n",
      "[Epoch 3/10] [Batch 0/1875] [D loss: 0.5966521501541138] [G loss: 0.7610928416252136]\n",
      "[Epoch 3/10] [Batch 100/1875] [D loss: 0.7260419726371765] [G loss: 0.9021300077438354]\n",
      "[Epoch 3/10] [Batch 200/1875] [D loss: 0.6943256855010986] [G loss: 1.534029483795166]\n",
      "[Epoch 3/10] [Batch 300/1875] [D loss: 0.6388461589813232] [G loss: 0.9475922584533691]\n",
      "[Epoch 3/10] [Batch 400/1875] [D loss: 0.6053922772407532] [G loss: 1.0602562427520752]\n",
      "[Epoch 3/10] [Batch 500/1875] [D loss: 0.634109377861023] [G loss: 1.1627473831176758]\n",
      "[Epoch 3/10] [Batch 600/1875] [D loss: 0.688384473323822] [G loss: 0.910497784614563]\n",
      "[Epoch 3/10] [Batch 700/1875] [D loss: 0.6401392221450806] [G loss: 1.0724588632583618]\n",
      "[Epoch 3/10] [Batch 800/1875] [D loss: 0.69389808177948] [G loss: 1.3193409442901611]\n",
      "[Epoch 3/10] [Batch 900/1875] [D loss: 0.5812362432479858] [G loss: 1.2660768032073975]\n",
      "[Epoch 3/10] [Batch 1000/1875] [D loss: 0.5848088264465332] [G loss: 1.7817983627319336]\n",
      "[Epoch 3/10] [Batch 1100/1875] [D loss: 0.6427794694900513] [G loss: 1.0174992084503174]\n",
      "[Epoch 3/10] [Batch 1200/1875] [D loss: 0.6561309695243835] [G loss: 0.9250956773757935]\n",
      "[Epoch 3/10] [Batch 1300/1875] [D loss: 0.5922335386276245] [G loss: 1.2752388715744019]\n",
      "[Epoch 3/10] [Batch 1400/1875] [D loss: 0.6512660384178162] [G loss: 0.9671979546546936]\n",
      "[Epoch 3/10] [Batch 1500/1875] [D loss: 0.569887638092041] [G loss: 1.1274609565734863]\n",
      "[Epoch 3/10] [Batch 1600/1875] [D loss: 0.6238155961036682] [G loss: 1.0581247806549072]\n",
      "[Epoch 3/10] [Batch 1700/1875] [D loss: 0.6550664305686951] [G loss: 1.1265803575515747]\n",
      "[Epoch 3/10] [Batch 1800/1875] [D loss: 0.6515795588493347] [G loss: 0.8337286710739136]\n",
      "[Epoch 4/10] [Batch 0/1875] [D loss: 0.6482143402099609] [G loss: 1.3628673553466797]\n",
      "[Epoch 4/10] [Batch 100/1875] [D loss: 0.6624830961227417] [G loss: 1.1143070459365845]\n",
      "[Epoch 4/10] [Batch 200/1875] [D loss: 0.6393647789955139] [G loss: 1.5678383111953735]\n",
      "[Epoch 4/10] [Batch 300/1875] [D loss: 0.6449143886566162] [G loss: 1.25564706325531]\n",
      "[Epoch 4/10] [Batch 400/1875] [D loss: 0.5446118116378784] [G loss: 1.234161376953125]\n",
      "[Epoch 4/10] [Batch 500/1875] [D loss: 0.6609419584274292] [G loss: 1.3785687685012817]\n",
      "[Epoch 4/10] [Batch 600/1875] [D loss: 0.5780876874923706] [G loss: 0.9805845618247986]\n",
      "[Epoch 4/10] [Batch 700/1875] [D loss: 0.6454308032989502] [G loss: 1.1653145551681519]\n",
      "[Epoch 4/10] [Batch 800/1875] [D loss: 0.6308691501617432] [G loss: 1.058674693107605]\n",
      "[Epoch 4/10] [Batch 900/1875] [D loss: 0.6210229396820068] [G loss: 1.1241405010223389]\n",
      "[Epoch 4/10] [Batch 1000/1875] [D loss: 0.612488865852356] [G loss: 1.00691819190979]\n",
      "[Epoch 4/10] [Batch 1100/1875] [D loss: 0.6437252759933472] [G loss: 1.0257819890975952]\n",
      "[Epoch 4/10] [Batch 1200/1875] [D loss: 0.5427066087722778] [G loss: 1.1794863939285278]\n",
      "[Epoch 4/10] [Batch 1300/1875] [D loss: 0.7213448882102966] [G loss: 0.9187273383140564]\n",
      "[Epoch 4/10] [Batch 1400/1875] [D loss: 0.5992311239242554] [G loss: 1.2994368076324463]\n",
      "[Epoch 4/10] [Batch 1500/1875] [D loss: 0.607978343963623] [G loss: 1.2335312366485596]\n",
      "[Epoch 4/10] [Batch 1600/1875] [D loss: 0.6116900444030762] [G loss: 1.1386990547180176]\n",
      "[Epoch 4/10] [Batch 1700/1875] [D loss: 0.6313642263412476] [G loss: 0.87935471534729]\n",
      "[Epoch 4/10] [Batch 1800/1875] [D loss: 0.6492853760719299] [G loss: 1.3086590766906738]\n",
      "[Epoch 5/10] [Batch 0/1875] [D loss: 0.6222326755523682] [G loss: 1.0770686864852905]\n",
      "[Epoch 5/10] [Batch 100/1875] [D loss: 0.6400375366210938] [G loss: 0.9359142184257507]\n",
      "[Epoch 5/10] [Batch 200/1875] [D loss: 0.597045361995697] [G loss: 1.168386459350586]\n",
      "[Epoch 5/10] [Batch 300/1875] [D loss: 0.6460628509521484] [G loss: 1.0031774044036865]\n",
      "[Epoch 5/10] [Batch 400/1875] [D loss: 0.641463041305542] [G loss: 1.2787631750106812]\n",
      "[Epoch 5/10] [Batch 500/1875] [D loss: 0.5936518907546997] [G loss: 1.0118743181228638]\n",
      "[Epoch 5/10] [Batch 600/1875] [D loss: 0.5598599910736084] [G loss: 1.1442172527313232]\n",
      "[Epoch 5/10] [Batch 700/1875] [D loss: 0.6003201603889465] [G loss: 0.9771518707275391]\n",
      "[Epoch 5/10] [Batch 800/1875] [D loss: 0.5941992998123169] [G loss: 1.2917306423187256]\n",
      "[Epoch 5/10] [Batch 900/1875] [D loss: 0.6874810457229614] [G loss: 1.060313105583191]\n",
      "[Epoch 5/10] [Batch 1000/1875] [D loss: 0.6713153123855591] [G loss: 0.8655856251716614]\n",
      "[Epoch 5/10] [Batch 1100/1875] [D loss: 0.7105456590652466] [G loss: 1.0379054546356201]\n",
      "[Epoch 5/10] [Batch 1200/1875] [D loss: 0.6015537977218628] [G loss: 1.1474556922912598]\n",
      "[Epoch 5/10] [Batch 1300/1875] [D loss: 0.602238655090332] [G loss: 1.1106648445129395]\n",
      "[Epoch 5/10] [Batch 1400/1875] [D loss: 0.6701686978340149] [G loss: 1.061226487159729]\n",
      "[Epoch 5/10] [Batch 1500/1875] [D loss: 0.6029171943664551] [G loss: 0.902519166469574]\n",
      "[Epoch 5/10] [Batch 1600/1875] [D loss: 0.6201304197311401] [G loss: 1.2077521085739136]\n",
      "[Epoch 5/10] [Batch 1700/1875] [D loss: 0.625921368598938] [G loss: 0.9681901931762695]\n",
      "[Epoch 5/10] [Batch 1800/1875] [D loss: 0.6240791082382202] [G loss: 0.9416013360023499]\n",
      "[Epoch 6/10] [Batch 0/1875] [D loss: 0.5945892333984375] [G loss: 1.1980278491973877]\n",
      "[Epoch 6/10] [Batch 100/1875] [D loss: 0.6216655373573303] [G loss: 0.9709984660148621]\n",
      "[Epoch 6/10] [Batch 200/1875] [D loss: 0.6037536859512329] [G loss: 1.0256609916687012]\n",
      "[Epoch 6/10] [Batch 300/1875] [D loss: 0.6407889127731323] [G loss: 0.9453262686729431]\n",
      "[Epoch 6/10] [Batch 400/1875] [D loss: 0.6440960168838501] [G loss: 0.8197101354598999]\n",
      "[Epoch 6/10] [Batch 500/1875] [D loss: 0.6479425430297852] [G loss: 1.1815924644470215]\n",
      "[Epoch 6/10] [Batch 600/1875] [D loss: 0.6576625108718872] [G loss: 0.9524644613265991]\n",
      "[Epoch 6/10] [Batch 700/1875] [D loss: 0.6251933574676514] [G loss: 1.1454217433929443]\n",
      "[Epoch 6/10] [Batch 800/1875] [D loss: 0.6420197486877441] [G loss: 0.9245699048042297]\n",
      "[Epoch 6/10] [Batch 900/1875] [D loss: 0.659337043762207] [G loss: 0.9782347679138184]\n",
      "[Epoch 6/10] [Batch 1000/1875] [D loss: 0.710519552230835] [G loss: 1.097145915031433]\n",
      "[Epoch 6/10] [Batch 1100/1875] [D loss: 0.7067630290985107] [G loss: 0.8547304272651672]\n",
      "[Epoch 6/10] [Batch 1200/1875] [D loss: 0.619806170463562] [G loss: 0.934346616268158]\n",
      "[Epoch 6/10] [Batch 1300/1875] [D loss: 0.6877032518386841] [G loss: 0.9580437541007996]\n",
      "[Epoch 6/10] [Batch 1400/1875] [D loss: 0.6150230169296265] [G loss: 0.9750410914421082]\n",
      "[Epoch 6/10] [Batch 1500/1875] [D loss: 0.6801164150238037] [G loss: 1.0192309617996216]\n",
      "[Epoch 6/10] [Batch 1600/1875] [D loss: 0.6846853494644165] [G loss: 1.0426025390625]\n",
      "[Epoch 6/10] [Batch 1700/1875] [D loss: 0.702256441116333] [G loss: 0.9949769973754883]\n",
      "[Epoch 6/10] [Batch 1800/1875] [D loss: 0.6122735738754272] [G loss: 0.9649678468704224]\n",
      "[Epoch 7/10] [Batch 0/1875] [D loss: 0.6606563329696655] [G loss: 0.9925879240036011]\n",
      "[Epoch 7/10] [Batch 100/1875] [D loss: 0.645024299621582] [G loss: 1.1773008108139038]\n",
      "[Epoch 7/10] [Batch 200/1875] [D loss: 0.6401375532150269] [G loss: 0.9153751134872437]\n",
      "[Epoch 7/10] [Batch 300/1875] [D loss: 0.6913763284683228] [G loss: 0.7943583130836487]\n",
      "[Epoch 7/10] [Batch 400/1875] [D loss: 0.6126323938369751] [G loss: 0.9672577381134033]\n",
      "[Epoch 7/10] [Batch 500/1875] [D loss: 0.6328074336051941] [G loss: 0.8277608156204224]\n",
      "[Epoch 7/10] [Batch 600/1875] [D loss: 0.6587098836898804] [G loss: 0.9728575944900513]\n",
      "[Epoch 7/10] [Batch 700/1875] [D loss: 0.6348565220832825] [G loss: 1.0257412195205688]\n",
      "[Epoch 7/10] [Batch 800/1875] [D loss: 0.6972013711929321] [G loss: 1.0081510543823242]\n",
      "[Epoch 7/10] [Batch 900/1875] [D loss: 0.6671993732452393] [G loss: 1.0182048082351685]\n",
      "[Epoch 7/10] [Batch 1000/1875] [D loss: 0.5881868600845337] [G loss: 0.9943587183952332]\n",
      "[Epoch 7/10] [Batch 1100/1875] [D loss: 0.6022422313690186] [G loss: 1.1161322593688965]\n",
      "[Epoch 7/10] [Batch 1200/1875] [D loss: 0.5852311849594116] [G loss: 0.9412266612052917]\n",
      "[Epoch 7/10] [Batch 1300/1875] [D loss: 0.6380068063735962] [G loss: 0.9006472229957581]\n",
      "[Epoch 7/10] [Batch 1400/1875] [D loss: 0.7007814645767212] [G loss: 0.9593208432197571]\n",
      "[Epoch 7/10] [Batch 1500/1875] [D loss: 0.6016967296600342] [G loss: 0.8563567996025085]\n",
      "[Epoch 7/10] [Batch 1600/1875] [D loss: 0.676948606967926] [G loss: 0.9273414015769958]\n",
      "[Epoch 7/10] [Batch 1700/1875] [D loss: 0.6514089107513428] [G loss: 1.021066665649414]\n",
      "[Epoch 7/10] [Batch 1800/1875] [D loss: 0.6595953702926636] [G loss: 0.9542896151542664]\n",
      "[Epoch 8/10] [Batch 0/1875] [D loss: 0.6794856786727905] [G loss: 0.9304500222206116]\n",
      "[Epoch 8/10] [Batch 100/1875] [D loss: 0.6773806810379028] [G loss: 0.9199937582015991]\n",
      "[Epoch 8/10] [Batch 200/1875] [D loss: 0.6439677476882935] [G loss: 0.9669205546379089]\n",
      "[Epoch 8/10] [Batch 300/1875] [D loss: 0.6560666561126709] [G loss: 0.972743034362793]\n",
      "[Epoch 8/10] [Batch 400/1875] [D loss: 0.6562516689300537] [G loss: 0.9203698635101318]\n",
      "[Epoch 8/10] [Batch 500/1875] [D loss: 0.6819911003112793] [G loss: 1.0233502388000488]\n",
      "[Epoch 8/10] [Batch 600/1875] [D loss: 0.6611146926879883] [G loss: 0.9561829566955566]\n",
      "[Epoch 8/10] [Batch 700/1875] [D loss: 0.6874357461929321] [G loss: 0.824148952960968]\n",
      "[Epoch 8/10] [Batch 800/1875] [D loss: 0.6454447507858276] [G loss: 0.8594627976417542]\n",
      "[Epoch 8/10] [Batch 900/1875] [D loss: 0.6823513507843018] [G loss: 0.7778809070587158]\n",
      "[Epoch 8/10] [Batch 1000/1875] [D loss: 0.708708643913269] [G loss: 0.9107379913330078]\n",
      "[Epoch 8/10] [Batch 1100/1875] [D loss: 0.6608916521072388] [G loss: 0.8622540235519409]\n",
      "[Epoch 8/10] [Batch 1200/1875] [D loss: 0.6505284309387207] [G loss: 0.9517253041267395]\n",
      "[Epoch 8/10] [Batch 1300/1875] [D loss: 0.6858055591583252] [G loss: 0.8048897981643677]\n",
      "[Epoch 8/10] [Batch 1400/1875] [D loss: 0.6882153153419495] [G loss: 0.9137800931930542]\n",
      "[Epoch 8/10] [Batch 1500/1875] [D loss: 0.6721104383468628] [G loss: 1.008833646774292]\n",
      "[Epoch 8/10] [Batch 1600/1875] [D loss: 0.6579343676567078] [G loss: 0.9819360971450806]\n",
      "[Epoch 8/10] [Batch 1700/1875] [D loss: 0.6525866985321045] [G loss: 0.9354479908943176]\n",
      "[Epoch 8/10] [Batch 1800/1875] [D loss: 0.6139132976531982] [G loss: 1.0704184770584106]\n",
      "[Epoch 9/10] [Batch 0/1875] [D loss: 0.6475329399108887] [G loss: 0.9462856650352478]\n",
      "[Epoch 9/10] [Batch 100/1875] [D loss: 0.5980614423751831] [G loss: 1.0293972492218018]\n",
      "[Epoch 9/10] [Batch 200/1875] [D loss: 0.7062290906906128] [G loss: 0.9317891001701355]\n",
      "[Epoch 9/10] [Batch 300/1875] [D loss: 0.6737658977508545] [G loss: 0.9575327634811401]\n",
      "[Epoch 9/10] [Batch 400/1875] [D loss: 0.6175411939620972] [G loss: 1.0198707580566406]\n",
      "[Epoch 9/10] [Batch 500/1875] [D loss: 0.6698553562164307] [G loss: 0.906453013420105]\n",
      "[Epoch 9/10] [Batch 600/1875] [D loss: 0.6369064450263977] [G loss: 0.8831787109375]\n",
      "[Epoch 9/10] [Batch 700/1875] [D loss: 0.6285567283630371] [G loss: 0.8221931457519531]\n",
      "[Epoch 9/10] [Batch 800/1875] [D loss: 0.6894491910934448] [G loss: 0.697252631187439]\n",
      "[Epoch 9/10] [Batch 900/1875] [D loss: 0.6696046590805054] [G loss: 0.9046779274940491]\n",
      "[Epoch 9/10] [Batch 1000/1875] [D loss: 0.6882386207580566] [G loss: 0.854188084602356]\n",
      "[Epoch 9/10] [Batch 1100/1875] [D loss: 0.6570228338241577] [G loss: 0.9970511794090271]\n",
      "[Epoch 9/10] [Batch 1200/1875] [D loss: 0.7209960222244263] [G loss: 0.8053774237632751]\n",
      "[Epoch 9/10] [Batch 1300/1875] [D loss: 0.6412029266357422] [G loss: 0.8251255750656128]\n",
      "[Epoch 9/10] [Batch 1400/1875] [D loss: 0.7315595149993896] [G loss: 0.892288863658905]\n",
      "[Epoch 9/10] [Batch 1500/1875] [D loss: 0.6433424949645996] [G loss: 0.8842065930366516]\n",
      "[Epoch 9/10] [Batch 1600/1875] [D loss: 0.661214292049408] [G loss: 0.9669393301010132]\n",
      "[Epoch 9/10] [Batch 1700/1875] [D loss: 0.6745204925537109] [G loss: 0.8448851108551025]\n",
      "[Epoch 9/10] [Batch 1800/1875] [D loss: 0.6533787846565247] [G loss: 0.9024467468261719]\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo mô hình, bộ tối ưu và hàm loss\n",
    "generator = Generator(latent_size, num_channels, image_size)\n",
    "discriminator = Discriminator(num_channels, image_size)\n",
    "cgan = cGAN(generator, discriminator)\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "# Huấn luyện\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(data_loader):\n",
    "        valid = torch.ones(imgs.size(0), 1)\n",
    "        fake = torch.zeros(imgs.size(0), 1)\n",
    "\n",
    "        # Huấn luyện Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        z = torch.randn(imgs.size(0), latent_size)\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        real_loss = adversarial_loss(discriminator(imgs), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Huấn luyện Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        gen_imgs = generator(z)\n",
    "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\n",
    "                f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(data_loader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "qovXzvQuCpmB",
    "outputId": "7c748d05-556e-40f3-e4fe-9f5b2d71d915"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tạo ảnh mới từ generator\n",
    "n_images = 4\n",
    "z = torch.randn(n_images, latent_size)\n",
    "generated_images = generator(z)\n",
    "\n",
    "# Hiển thị ảnh\n",
    "fig, axs = plt.subplots(1, n_images, figsize=(20, 2))\n",
    "\n",
    "for i in range(n_images):\n",
    "    axs[i].imshow(generated_images[i].detach().view(image_size, image_size), cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhH-590kTbXl"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZH-lVrvCsJA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
